Welcome to STA 360, Fall 2020! 

The readings for the class can be found below. These are subject to change and will be updated as the course progresses. 

The readings are from Hoff and also in notes that I have written myself. You'll notice that some of the material covered in class are from these notes. I expect you to have read before you come to class and have reviewed the notes from the previous lectures. I highly recommend that you read _all of Hoff. It's a great book to read. 

Preparation for the Course:

Before starting the course for the fall semester, I would highly recommend the following:
+ Review pre-req material for the course on the syllabus. https://github.com/resteorts/modern-bayes/blob/master/syllabus/syllabus-sta360-fall20.pdf 
+ Review R: 

- Part I: https://github.com/resteorts/modern-bayes/blob/master/lecturesModernBayes20/background-intro-to-R/introToR-partI.pdf
- Part II: https://github.com/resteorts/modern-bayes/blob/master/lecturesModernBayes20/background-intro-to-R/introToR-partII.pdf
- Part III: https://github.com/resteorts/modern-bayes/blob/master/lecturesModernBayes20/background-intro-to-R/introToR-partIII.pdf
- Part IV: https://github.com/resteorts/modern-bayes/blob/master/lecturesModernBayes20/background-intro-to-R/introToR-partIV.pdf
- Part V: https://github.com/resteorts/modern-bayes/blob/master/lecturesModernBayes20/background-intro-to-R/introToR-partV.pdf
- Videos: https://github.com/resteorts/modern-bayes/tree/master/lecturesModernBayes20/background-intro-to-R/videos

Reference Text: http://shop.oreilly.com/product/9780596809164.do (The R Cookbook, not to be confused with the one for graphics). 
+ Learn github as this is where the course resources will be located. https://lab.github.com/)

## Tenative Course Schedule 

(Please note that this is subject to change given that we still do not have a class time, location for Fall 2020 yet, but I will update this often leading up to the first day of class to try and make this a smooth semester for all. I appreciate everyone's patience as we all go through this together. Importantly, know that I care very much your learning and appreciate your feedback! I look forward to having you in class very much, and hope that we're all in person like we were before as soon as possible! 

<pre><b> Week 1: Tuesday, August 18 - Thursday, August 20 </pre>
- Lecture 1: Tuesday, August 18: Module 0: Introduction to Course and Expectations
- Lecture 1 Slides: https://github.com/resteorts/modern-bayes-virtual/blob/master/lecturesModernBayes20/lecture-0/00-intro-to-Bayes.pdf
- Lab 1: Introduction to R 
- Lecture 2: Thursday, August 20, Module 1: History of Bayes and Introduction to Bayesian Statistics
- Lecture 2 Slides: https://github.com/resteorts/modern-bayes-virtual/blob/master/lecturesModernBayes20/lecture-1/01-history-of-Bayes.pdf

<pre><b> Week 2: Tuesday, August 25 - Thursday, August 27 </pre>
- Lecture 3: Tuesday, August 25: Module 1: History of Bayes and Introduction to Bayesian Statistics
- Lecture 3 Slides: https://github.com/resteorts/modern-bayes-virtual/blob/master/lecturesModernBayes20/lecture-1/01-history-of-Bayes.pdf
- Lab 2: Introduction to Bayes 
- Lecture 4: Thursday, August 27: Module 1: Introduction to Bayesian Statistics (Continued) 
- Lecture 4 Slides: https://github.com/resteorts/modern-bayes-virtual/blob/master/lecturesModernBayes20/lecture-1/01-intro-to-Bayes.pdf

Reading: Read Ch 1, Ch 2.1 -- 2.6. (Hoff), Read Ch 1.1 (http://www2.stat.duke.edu/~rcs46/books/bayes_manuscripts.pdf)

<pre><b> Week 3: Tuesday, September 1 - Thursday, September 3 </pre>
- Lecture 5: Tuesday September 1: Module 1:  Introduction to Bayesian Statistics (Continued) 
- Lecture 5 Slides: - Lecture 5 Slides: https://github.com/resteorts/modern-bayes-virtual/blob/master/lecturesModernBayes20/lecture-1/01-intro-to-Bayes.pdf
- Lab 2: Introduction to Bayes (Continued) 
- Lecture 6: Thursday September 3: Module 1: Introduction to Bayesian Statistics (Continued) 
- Lecture 6 Slides: - Lecture 6 Slides: https://github.com/resteorts/modern-bayes-virtual/blob/master/lecturesModernBayes20/lecture-1/01-intro-to-Bayes.pdf

Reading:
Read Ch 3 (Hoff) 
Read Ch 2.5--2.7 (http://www2.stat.duke.edu/~rcs46/books/bayes_manuscripts.pdf)
Read Ch 4 for predictive inference (Hoff). 
Read Ch 2.9 (Posterior predictive inference) (http://www2.stat.duke.edu/~rcs46/books/bayes_manuscripts.pdf). 


<pre><b> Week 4: Tuesday, September 8 - Thursday, September 10 </pre>
- Lecture 7: Tuesday September 8: Module 2:  Introduction to Decision Theory 
- Lecture 7 Slides: https://github.com/resteorts/modern-bayes-virtual/blob/master/lecturesModernBayes20/lecture-2/02-intro-to-Bayes.pdf
- Lab 3: Introduction to Decision Theory
- Lecture 8: Thursday September 10: Module 2: Introduction to Decision Theory (Continued)
- Lecture 8 Slides: https://github.com/resteorts/modern-bayes-virtual/blob/master/lecturesModernBayes20/lecture-2/02-intro-to-Bayes.pdf

Reading:  Read Ch 2.1 -- 2.4 (http://www2.stat.duke.edu/~rcs46/books/bayes_manuscripts.pdf)
This is not covered in Hoff. 

<pre><b> Week 5: Tuesday, September 15 - Thursday, September 17 </pre>
- Exam I given. Details to be released. 

<pre><b> Week 6: Tuesday, September 22 - Thursday, September 24 </pre>
- Lecture 9: Tuesday September 22: Module 3:  Advanced Conjucacy (Normal-Normal)
- Lecture 9 Slides: https://github.com/resteorts/modern-bayes-virtual/blob/master/lecturesModernBayes20/lecture-3/03-normal-distribution.pdf
- Lab 4: Introduction to Gaussian Conjugate Models 
- Lecture 10: Thursday September 24: Module 3: Advanced Conjucacy (Normal-Normal) (Continued)
- Lecture 10 Slides: https://github.com/resteorts/modern-bayes-virtual/blob/master/lecturesModernBayes20/lecture-3/03-normal-distribution.pdf

Reading:  Ch 2, Example 2.7 and 2.8 (in terms of variance derivations), (http://www2.stat.duke.edu/~rcs46/books/bayes_manuscripts.pdf). This covers the Normal-normal conjugate model. 

<pre><b> Week 7: Tuesday, September 29 - Thursday, October 1 </pre>
- Lecture 10: Tuesday September 29: Module 4:  Advanced Conjucacy (Normal-Gamma)
- Lecture 10 Slides: https://github.com/resteorts/modern-bayes-virtual/blob/master/lecturesModernBayes20/lecture-4/04-normal-gamma.pdf
- Lab 4: Introduction to Normal-Gamma Conjugate Models 
- Lecture 11: Thursday October 1: Module 4: Advanced Conjucacy (Normal-Gamma) (Continued)
- Lecture 11 Slides: https://github.com/resteorts/modern-bayes-virtual/blob/master/lecturesModernBayes20/lecture-4/04-normal-gamma.pdf

Reading: Ch 2, Example 2.13, (http://www2.stat.duke.edu/~rcs46/books/bayes_manuscripts.pdf)
 
 <pre><b>  Week 8: Tuesday, October 6 - Thursday, October 8 </pre>
 - Lecture 12: Tuesday October 6: Module 5:  Introduction to Monte Carlo
 - Lecture 12 Slides: https://github.com/resteorts/modern-bayes-virtual/blob/master/lecturesModernBayes20/lecture-5/05-monte-carlo.pdf
 - Lab 5: Introduction to Importance and Rejection Sampling 
 - Lecture 13: Thursday October 8: Module 5:  Introduction to Monte Carlo (Continued)
 - Lecture 13 Slides: https://github.com/resteorts/modern-bayes-virtual/blob/master/lecturesModernBayes20/lecture-5/05-monte-carlo.pdf

Reading: 
Module 5 (Introduction to Monte Carlo):
Read Hoff, Chapter 4. 
Read PhD notes, Chapter 5.1, 5.3
Remark: The slides will cover examples not always in Hoff or the notes. 

Modules 6--7 (One Stage Gibbs Sampling and the Metropolis Algorithm)
Read Hoff, Ch 6
Read Phd notes, Chapter 5.2
Remark: The slides will cover examples not always in Hoff or the notes.  
For Metropolis Algorithm, read Hoff 10.2 

 <pre><b> Week 9: Tuesday, October 13 - Thursday, October 15 </pre>
- Lecture 14: Tuesday October 13: Module 6:  The Metropolis Algorithm 
- Lecture 14 Slides: https://github.com/resteorts/modern-bayes-virtual/blob/master/lecturesModernBayes20/lecture-6/06-metropolis.pdf
- Lab 6: The Metropolis Algorithm
- Lecture 15: Thursday October 15: Module 6: The Metropolis Algorithm (Continued)
- Lecture 15 Slides: https://github.com/resteorts/modern-bayes-virtual/blob/master/lecturesModernBayes20/lecture-6/06-metropolis.pdf

<pre><b> Week 10: Tuesday, October 13 - Thursday, October 15 </pre>
- Lecture 14: Tuesday October 13: Module 6:  One Stage Gibbs Sampling and the Metropolis Algorithm (Continued)
- Lab 7: One Stage Gibbs Sampling 
- Lecture 15: Thursday October 15: Module 6: One Stage Gibbs Sampling and the Metropolis Algorithm

 <pre><b> Week 11: Tuesday, October 20 - Thursday, October 22 </pre>
- Lecture 16: Tuesday October 20: Module 7:  Intro to Gibbs 
- Lecture 16 Slides: https://github.com/resteorts/modern-bayes-virtual/blob/master/lecturesModernBayes20/lecture-7/07-gibbs-part1.pdf
- Lab 8: Multi-stage Gibbs sampling
- Lecture 17: Thursday October 22: Module 7:  Multi-stage Gibbs sampling and Missing Data
- Lecture 17 Slides: https://github.com/resteorts/modern-bayes-virtual/blob/master/lecturesModernBayes20/lecture-7/07-gibbs-part2-multi-stage.pdf

 <pre><b> Week 12: Tuesday, October 27 - Thursday, October 29 </pre>
- Lecture 17: Tuesday October 27: Module 7:  Data Augmentation 
- Lecture 17 Slides: https://github.com/resteorts/modern-bayes-virtual/blob/master/lecturesModernBayes20/lecture-7/07-gibbs-part3-data-augment.pdf
- Lab 9: XXXX
- Lecture 18: Thursday October 29: Module 7: Data Augmentation and Mixture Models 
- Lecture 18 Slides: https://github.com/resteorts/modern-bayes-virtual/blob/master/lecturesModernBayes20/lecture-7/07-gibbs-part4-data-augment.pdf

Reading: Module 7  (Multistage Gibbs and Latent Variable Allocation)
The material in class is not in the PhD notes for the most part. 
(Note: I will not be following the book with regards to the examples in Hoff
but I do recommend reading them).  Gibbs reading: You should have already read Ch 6, so review as need be. 
Metropolis Hastings: 10.4 and 10.5, Latent variable allocation: Chapter 12

<pre><b> Week 13: Tuesday, November 3 - Thursday, November 5 </pre>
- Exam II: Details to be released. 

<pre><b> Week 14: Tuesday, November 10 - Thursday, November 12 </pre>
- Lecture 19: Tuesday November 10: Module 8:  Multivariate Normal Distribution
- Lecture 19 Slides: https://github.com/resteorts/modern-bayes-virtual/blob/master/lecturesModernBayes20/lecture-8/08-multivariate-norm.pdf
- Lab 9: Multivariate Normal
- Lecture 20: Thursday November 12: Module 8: Data Augmentation and Mixture Models 
- Lecture 20 Slides: https://github.com/resteorts/modern-bayes-virtual/blob/master/lecturesModernBayes20/lecture-8/08-missing-data.pdf

Readings: Module 9 (Multivariate Normal Distribution)
Hoff: Chapter 7.1--7.4

<pre><b> Week 15: Tuesday, November 17 - Thursday, November 19 </pre>
- Lecture 21: Tuesday November 17: Module 9:  Linear Regression 
- Lecture 21 Slides: https://github.com/resteorts/modern-bayes-virtual/blob/master/lecturesModernBayes20/lecture-9/9-linear-regression.pdf
- Lab 9: Linear Regression 
- Lecture 22: Thursday November 19: Module 9: Probit Regression 
- Lecture 22 Slides: https://github.com/resteorts/modern-bayes-virtual/blob/master/lecturesModernBayes20/lecture-9/9-probit-regression.pdf

Readings: Module 11 (Linear Regression)
Hoff: Chapter 9.1--9.2

<pre><b> Week 16: Tuesday, November 24 - Thursday, November 26 </pre>
- Lecture 21: Tuesday November 24: Module 10:  Model Selection 
- Lecture 21 Slides: https://github.com/resteorts/modern-bayes-virtual/blob/master/lecturesModernBayes20/lecture-10/10-model-selection.pdf
- Lab 9: Linear Regression 
- Lecture 22: Thursday November 26: Module 10: Model Selection (Continued) 
- Lecture 22 Slides: https://github.com/resteorts/modern-bayes-virtual/blob/master/lecturesModernBayes20/lecture-10/10-model-selection.pdf


Other readings :

- Credible Intervals): Cred intervals are covered on pages 52 and 267 of Hoff. 
- Read Ch 4.1--4.1 (Cred intervals) (http://www2.stat.duke.edu/~rcs46/books/bayes_manuscripts.pdf)
- Here is a brief intro from PSU on Multinomial sampling for a review: 
https://onlinecourses.science.psu.edu/stat504/node/59
