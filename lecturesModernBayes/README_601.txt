22 Lectures. Planned outline for semester of topics per lecture

# Structure. Go over the first homework with them and expectations of grading. 


Module 0: Introduction to R: They will do this on their own time. 

Module 1: Why Bayesian? Intro to Bayes and conjugate priors. Example of a sleep study. (Lectures 1 and 2). 
Lab 1: Beta-Binomial Distribution. 
Homework 1 is already out.  

Module  2: Decision Theory (Lecture 3)

Module  3: More Advanced Bayesian Methods: What can we do with conjugacy? (Lecture 4, 5)
Lab: Prior predictive checks and credible intervals. 

Module  4: Being Objective. 
Lab: Looking at many objective priors. Simulation studies. 

Module  5: Intro to Monte Carlo I: Importance sampling (Lecture 8)
Module  6: Intro to Monte Carlo II: Rejection sampling 
Module  7: Intro to MCMC: One stage Gibbs sampler
Module  8: Intro to MCMC: One stage Gibbs sampler (continued) 

Module  9:  Two stage Gibbs sampler
Module  10: Examples of Gibbs sampling
Lecture 11: I need to look at Hoff and write more notes
Module  12: Multivariate Distributions: Multivariate Normal and inverse Wishart
Module  13: Imputation 
Module  14: Linear Regression 
Module  15: Metropolis
I honestly think stopping here and then doing some BNP would be good
(or special topics given the time). 
I could try and cram in GLMs but I think that they'll be able to pick this up rather easily. I could drop decision theory, but I think this is worth seeing + objective Bayes (
these aren't really in Hoff but I think the students should see them). 
Decision theory: I think they should see loss and risk
Objective: I think they should know the basic concept and what Jeffreys' prior is. Nothing beyond this.

prior predictive checks
https://www.cs.princeton.edu/courses/archive/fall11/cos597C/lectures/ppc.pdf


