
---
title: "Module 9: The Multivariate Normal Distribution"
author: "Rebecca C. Steorts"
output: 
     beamer_presentation:
      includes: 
          in_header: custom2.tex
font-size: 8px
---

Rest of semester
===
- Last day of class is Tuesday, April 18
- Last homework is HW 7 (see Sakai). This goes along with Lab 6. 
- For HW 7, your TAs have gone over tasks 1-3 with you and posted solutions are available. 
- Code has been posted for Task 4 - 5. 
- TAs will help with the remainder of the assignment in lab on April 12. If you miss lab, no reviews will be done. 

Final exam
===
- \textcolor{blue}{You may bring a cheat sheet into the exam (front and back). It must be a standard 9 in by 11 inch side piece of paper. You must turn this in with your final exam.}
- Final exam is posted on the syllabus (no make ups). May 4, 7--10, Old Chem 116. 
- Final exam is cumulative and will be similar to exam I. 
- Practice problems have now been posted. Solutions will be posted after April 19th.
- I will do a review class on Tuesday, April 25. This is optional. 

Agenda
===
\begin{itemize}
\item Moving from univariate to multivariate distributions. 
\item The multivariate normal (MVN) distribution.
\item Conjugate for the MVN distribution.
\item The inverse Wishart distribution. 
\item Conjugate for the MVN distribution (but on the covariance matrix). 
\item Combining the MVN with inverse Wishart. 
\item See Chapter 7 (Hoff) for a review of the standard Normal density.
\end{itemize}

Notation
===
Assume a matrix of covariates

$$\bm{X}_{n \times p} = 
\left( \begin{array}{cccc}
x_{11} & x_{12} & \ldots&  x_{1p}\\
x_{21} & x_{22} & \ldots& x_{2p} \\
x_{i1} & x_{i2} & \ldots& x_{ip} \\
\vdots & \vdots & \ddots & \vdots \\
x_{n1} & x_{n2} &\ldots& x_{np}
\end{array} \right).
$$

- A column of x represents a particular covariate we might be interested in, such as age of a person. 

- Denote $x_i$ as the ith \textcolor{red}{row vector} of the $X_{n \times p}$ matrix. 

\[  x_{i}= \left( \begin{array}{c}
x_{i1}\\
x_{ip}\\
\vdots\\
x_{ip}
\end{array} \right) \]



Distribution of MVN
===
We assume that the population mean is $\bmu = E(\bX)$ and $\Sigma = \var(\bX) = E[(\bX - \bmu)(\bX - \bmu)^T],$ 
where 
\[  \bmu= \left( \begin{array}{c}
\mu_1\\
\mu_2\\
\vdots\\
\mu_p
\end{array} \right) \]
and 

$$\sig = 
\left( \begin{array}{cccc}
\sigma_1^2 & \sigma_{12} & \ldots&  \sigma_{1p}\\
\sigma_{21} & \sigma_2^2 & \ldots& \sigma_{2p}\\
\vdots & \vdots & \ddots & \vdots \\
\sigma_{p1} & \sigma_{p2} &\ldots& \sigma_p^2
\end{array} \right).
$$

Notation
===
Suppose matrix $A$  is invertible. The 
$$\det(A) = \sum_{i=1}^{j=n} a_{ij} A_{ij}.$$
\vskip 1em 

I recommend using the det() commend in R. 
\vskip 1em 

Suppose now we have a square matrix $H_{p \times p}.$

$$\text{trace}(H) = \sum_i h_{ii},$$ where $h_{ii}$ are the diagonal elements of $H.$

Notation
===
\begin{itemize}
\item MVN is generalization of univariate normal.
\item For the MVN, we write $\bX \sim
\mathcal{MVN}(\bmu,\Sigma)$. 
\item The $(i,j)^{\text{th}}$
component of $\Sigma$ is the covariance between $X_i$ and~$X_j$ (so
the diagonal of $\Sigma$ gives the component variances).
\end{itemize}

Example: $Cov(X_1, X_2)$ is just one element of the matrix $\Sigma.$

Multivariate Normal
===
Just as the probability density of a scalar normal is
\begin{equation}
p(x) = {\left(2\pi\sigma^2\right)}^{-1/2}\exp{\left\{ -\frac{1}{2} \frac{(x-\mu)^2}{\sigma^2}\right\}},
\end{equation}
the probability density of the multivariate normal is
\begin{equation}
p(\vec{x}) = {\left(2\pi\right)}^{-p/2}(\det{\Sigma})^{-1/2} \exp{\left\{-\frac{1}{2} (\bx-\bmu)^T\Sigma^{-1} (\bx - \bmu)\right\}}.
\end{equation}
\textcolor{blue}{Univariate normal is special case of the multivariate normal with a one-dimensional mean ``vector'' and a one-by-one variance ``matrix.''}

Standard Multivariate Normal Distribution
===
Consider $$Z_1,\ldots,Z_n \stackrel{iid}{\sim} MVN(0,I)$$

\begin{align}
f_z(z) &= \prod_{i=1}^n \frac{1}{2\pi} e^{-z_i^2/2}\\
& = (2\pi)^{-n} e^{z^Tz/2}
\end{align}

- E[Z] = 0
- Var[Z] = I

Conjugate to MVN
===
Suppose that $$X_1 \ldots X_n \stackrel{iid}{\sim} MVN(\theta, \Sigma). $$
Let $$\pi(\btheta) \sim MVN(\bmu, \Omega). $$

What is the full conditional distribution of $\btheta \mid \bX, \Sigma$?


Prior
===
\begin{align}
\pi(\btheta) &= {\left(2\pi\right)}^{-p/2}\det{\Omega}^{-1/2} \exp{\left\{-\frac{1}{2} (\btheta-\bmu)^T\Omega^{-1} (\btheta - \bmu)\right\}} \\
& \propto \exp{\left\{-\frac{1}{2} (\btheta-\bmu)^T\Omega^{-1} (\btheta - \bmu)\right\}} \\
& \propto \exp-\frac{1}{2} {\left \{\btheta^T\Omega^{-1} \btheta - 2 \btheta^T \Omega^{-1} \mu + \mu^T \Omega^{-1} \mu \right \}} \\
& \propto \exp-\frac{1}{2} {\left \{\btheta^T\Omega^{-1} \btheta - 2 \btheta^T \Omega^{-1} \mu  \right \}}\\
&= \exp-\frac{1}{2} {\left \{\btheta^TA_o \btheta - 2 \btheta^T  b_o  \right \}}
\end{align}
$\pi(\btheta) \sim MVN(\bmu, \Omega)$ implies that $A_o = \Omega^{-1}$ and $b_o = \Omega^{-1} \mu.$

Likelihood
===
\begin{align}
p(\bx \mid \btheta, \Sigma) &= \prod_{i=1}^n
{\left(2\pi\right)}^{-p/2}\det{\Sigma}^{-n/2} \exp{\left\{-\frac{1}{2} (x_i-\btheta)^T\Sigma^{-1} (x_i - \btheta)\right\}}\\
\propto 
& \exp-\frac{1}{2} {\left \{ \sum_i x_i^T \Sigma^{-1} x_i -2 \sum_i \btheta^T \Sigma^{-1} x_i + 
\sum_i \btheta^T\Sigma^{-1} \btheta 
 \right \}}\\
 & \exp-\frac{1}{2} {\left \{  -2 \btheta^T \Sigma^{-1} n\bar{x} + 
n \btheta^T\Sigma^{-1} \btheta 
 \right \}}\\
  & \exp-\frac{1}{2} {\left \{  -2 \btheta^T b_1+ 
\btheta^T A_1 \btheta \right \}},
\end{align}
where $$b_1= \Sigma^{-1} n\bar{x}, \quad A_1 = n\Sigma^{-1}$$ and 
$$\bar{x} := (\frac{1}{n}\sum_i x_{i1} ,\ldots, \frac{1}{n} \sum_i x_{ip})^T.$$

Full conditional
===
\begin{align}
p(\btheta \mid \bx, \Sigma) &\propto
p(\bx \mid \btheta, \Sigma) \times p(\btheta) \\
&\propto 
\exp-\frac{1}{2} {\left \{  -2 \btheta^T b_1+ 
\btheta^T A_1 \btheta \right \}} \\
&\times
\exp-\frac{1}{2} {\left \{\btheta^TA_o \btheta - 2 \btheta^T b_o  \right \}}\\
%%%
&\propto \exp\{\btheta^T b_1 - \frac{1}{2}\btheta^T A_1 \btheta- \frac{1}{2}\btheta^TA_o  \btheta
+ \btheta^T b_o\}\\
& \propto\exp\{
\btheta^T( b_o + b_1) -\frac{1}{2}\theta^T(A_o + A_1) \theta
\}
\end{align}
Then $$A_n = A_o + A_1 = \Omega^{-1}+n\Sigma^{-1}$$ and $$b_n = b_o + b_1 = \Omega^{-1}\mu + \Sigma^{-1} n\bar{x}$$
$$\btheta \mid \bx, \Sigma \sim MVN(A_n^{-1}b_n, A_n^{-1}) = MVN(\mu_n, \Sigma_n)$$

Interpretations
===
$$\btheta \mid \bx, \Sigma \sim MVN(A_n^{-1}b_n, A_n^{-1}) = MVN(\mu_n, \Sigma_n)$$
\begin{align}
\mu_n &= A_n^{-1}b_n = [\Omega^{-1}+n\Sigma^{-1}]^{-1}(b_o + b_1)\\
&=  [\Omega^{-1}+n\Sigma^{-1}]^{-1}(\Omega^{-1}\mu+ \Sigma^{-1} n\bar{x} )
\end{align}
\vskip 1em
\begin{align}
\Sigma_n &= A_n^{-1} = [\Omega^{-1}+n\Sigma^{-1}]^{-1}
\end{align}

inverse Wishart  distribution
===
Suppose $\Sigma \sim \text{inverseWishart}(\nu_o, S_o^{-1})$
where $\nu_o$ is a scalar and $S_o^{-1}$ is a matrix.
\vskip 1em

Then $$p(\Sigma) \propto
\det(\Sigma)^{-(\nu_o + p +1)/2} \times \exp\{
-\text{tr}(S_o\Sigma^{-1})/2
\}$$

\vskip 1em
For the full distribution, see Hoff, Chapter 7 (p. 110).

inverse Wishart distribution
===
\begin{itemize}
\item The inverse Wishart distribution is the multivariate version of the Gamma distribution. 
\item The full hierarchy we're interested in is 
$$\bm{X} \mid \btheta, \Sigma \sim MVN(\btheta, \Sigma).$$ 
$$ \btheta \sim MVN(\mu, \Omega)$$
$$ \Sigma \sim \text{inverseWishart}(\nu_o, S_o^{-1}).$$
\end{itemize}
We first consider the conjugacy of the MVN and the inverse Wishart, i.e.
$$\bm{X} \mid \btheta, \Sigma \sim MVN(\btheta, \Sigma).$$ 
$$ \Sigma \sim \text{inverseWishart}(\nu_o, S_o^{-1}).$$

Continued
===
What about $p(\Sigma \mid \bX,  \btheta) \; \textcolor{red}{\propto} \; p(\Sigma) \times p(\bX \mid \btheta, \Sigma).$
Let's first look at 
\begin{align}
&p(\bX \mid \btheta, \Sigma) \\
&\propto
\det(\Sigma)^{-n/2}\exp\{-
\sum_i (\bx_i - \btheta)^T\Sigma^{-1} (\bx_i - \btheta)/2
\}\\
&\propto
\det(\Sigma)^{-n/2}\exp\{- tr(
\sum_i  (\bx_i - \btheta)(\bx_i - \btheta)^T\Sigma^{-1}/2)
\}\\
&\propto 
\det(\Sigma)^{-n/2}\exp\{-
\text{tr}(S_\theta \Sigma^{-1}/2)
\}
\end{align}
where $S_\theta = \sum_i (\bx_i - \btheta) (\bx_i - \btheta)^T.$

Fact: $$\sum_k b_k^TA b_k = tr(B^T B A),$$ where B is the matrix whose $k$th row is $b_k.$



Continued
===
Now we can calculate $p(\Sigma \mid \bX,  \btheta)$
\begin{align}
&p(\Sigma \mid \bX,  \btheta) \\ & \quad= p(\Sigma) \times p(\bX \mid \btheta, \Sigma) \\
& \quad \propto 
\det(\Sigma)^{-(\nu_o + p +1)/2} \times \exp\{
-\text{tr}(S_o\Sigma^{-1})/2
\} \\
& \qquad \times
\det(\Sigma)^{-n/2}\exp\{-
\text{tr}(S_\theta \Sigma^{-1})/2\}\\
& \quad \propto 
\det(\Sigma)^{-(\nu_o + n + p +1)/2}
\exp\{-
\text{tr}((S_o +S_\theta) \Sigma^{-1})/2\}
\end{align}
This implies that 
$$\Sigma \mid \bX,  \btheta \sim \text{inverseWishart}(\nu_o + n, [S_o + S_\theta]^{-1} =: S_n)$$

Continued
===
Suppose that we wish now to take 

$$\btheta \mid \bX, \Sigma \sim MVN(\mu_n, \Sigma_n)$$ (which we finished an example on earlier).
Now let $$\Sigma \mid \bX, \btheta \sim \text{inverseWishart}(\nu_n, S_n^{-1})$$
\vskip 1em 
There is no closed form expression for this posterior. Solution?

Gibbs sampler
===
Suppose the Gibbs sampler is at iteration $s.$
\begin{enumerate}
\item Sample $\btheta^{(s+1)}$ from it's full conditional:
\begin{enumerate}
\item[a)] Compute $\mu_n$ and $\Sigma_n$ from $\bX$ and $\Sigma^{(s)}$
\item[b)] Sample $\btheta^{(s+1)}\sim MVN(\mu_n, \Sigma_n)$
\end{enumerate}
\item Sample $\Sigma^{(s+1)}$ from its full conditional:
\begin{enumerate}
\item[a)] Compute $S_n$ from $\bX$ and $\theta^{(s)}$
\item[b)] Sample $\Sigma^{(s+1)} \sim \text{inverseWishart}(\nu_n, S_n^{-1})$
\end{enumerate}
\end{enumerate}


Working with Multivariate Normal Distribution
===
The `R` package, `mvtnorm`, contains functions for evaluating and simulating from a multivariate normal density.

```{r}
library(mvtnorm)
```

Simulating Data
===
Simulate a single multivariate normal random vector using the `rmvnorm` function.

```{r}
rmvnorm(n = 1, mean = rep(0, 2), sigma = diag(2))
```


Evaluation
===
Evaluate the multivariate normal density at a single value using the `dmvnorm` function.

```{r}
dmvnorm(rep(0, 2), mean = rep(0, 2), sigma = diag(2))
```

Working with the Multivariate Normal
===
- Now let's simulate many multivariate normals. 
- Each row is a different sample from this multivariate normal distribution.
```{r}
rmvnorm(n = 3, mean = rep(0, 2), sigma = diag(2))
```

Evaluation
===
We can evaluate the multivariate normal density at several values using the `dmvnorm` function.

```{r}
dmvnorm(rbind(rep(0, 2), rep(1, 2), rep(2, 2)), 
        mean = rep(0, 2), sigma = diag(2))
```

Work with the Wishart density
===
- The `R` package, `stats`, contains functions for evaluating and simulating from a Wishart density.

- We can simulate a single Wishart distributed matrix using the `rWishart` function.

```{r}
nu0 <- 2
Sigma0 <- diag(2)
rWishart(1, df = nu0, Sigma = Sigma0)[, , 1]
```

inverse Wishart simulation
===
We can simulate a single inverse-Wishart distributed matrix using the `rWishart` function as well.

```{r}
nu0 <- 2
Sigma0 <- diag(2)
solve(rWishart(1, df = nu0, 
               Sigma = solve(Sigma0))[, , 1])
```

